{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abac0238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# models (linear regression, krr, xgb, tabPFN)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.kernel_ridge import KernelRidge #krr\n",
    "import xgboost as xgb #xgb\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6d3d79",
   "metadata": {},
   "source": [
    "#### <b>Load all data and run baseline models</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4faec1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>MaxEStateIndex</th>\n",
       "      <th>MinAbsEStateIndex</th>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <th>qed</th>\n",
       "      <th>SPS</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>HeavyAtomMolWt</th>\n",
       "      <th>ExactMolWt</th>\n",
       "      <th>...</th>\n",
       "      <th>spectral_radius</th>\n",
       "      <th>number_of_cycles</th>\n",
       "      <th>number_of_stars</th>\n",
       "      <th>diameter</th>\n",
       "      <th>number_of_branches</th>\n",
       "      <th>Tg</th>\n",
       "      <th>FFV</th>\n",
       "      <th>Tc</th>\n",
       "      <th>Density</th>\n",
       "      <th>Rg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*CC(*)c1ccccc1C(=O)OCCCCCC</td>\n",
       "      <td>12.144536</td>\n",
       "      <td>12.144536</td>\n",
       "      <td>0.105927</td>\n",
       "      <td>-0.105927</td>\n",
       "      <td>0.500278</td>\n",
       "      <td>13.705882</td>\n",
       "      <td>232.323</td>\n",
       "      <td>212.163</td>\n",
       "      <td>232.146330</td>\n",
       "      <td>...</td>\n",
       "      <td>2.347213</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.374645</td>\n",
       "      <td>0.205667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*Nc1ccc([C@H](CCC)c2ccc(C3(c4ccc([C@@H](CCC)c5...</td>\n",
       "      <td>3.523412</td>\n",
       "      <td>3.523412</td>\n",
       "      <td>0.098918</td>\n",
       "      <td>0.098918</td>\n",
       "      <td>0.125364</td>\n",
       "      <td>16.777778</td>\n",
       "      <td>598.919</td>\n",
       "      <td>544.487</td>\n",
       "      <td>598.428700</td>\n",
       "      <td>...</td>\n",
       "      <td>2.512983</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.370410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*Oc1ccc(S(=O)(=O)c2ccc(Oc3ccc(C4(c5ccc(Oc6ccc(...</td>\n",
       "      <td>13.714745</td>\n",
       "      <td>13.714745</td>\n",
       "      <td>0.107441</td>\n",
       "      <td>-3.829434</td>\n",
       "      <td>0.092387</td>\n",
       "      <td>16.301370</td>\n",
       "      <td>1003.207</td>\n",
       "      <td>952.807</td>\n",
       "      <td>1002.289625</td>\n",
       "      <td>...</td>\n",
       "      <td>2.494566</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.378860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*Nc1ccc(-c2c(-c3ccc(C)cc3)c(-c3ccc(C)cc3)c(N*)...</td>\n",
       "      <td>3.978671</td>\n",
       "      <td>3.978671</td>\n",
       "      <td>0.054569</td>\n",
       "      <td>-0.202102</td>\n",
       "      <td>0.209590</td>\n",
       "      <td>11.523810</td>\n",
       "      <td>542.726</td>\n",
       "      <td>508.454</td>\n",
       "      <td>542.272199</td>\n",
       "      <td>...</td>\n",
       "      <td>2.598093</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.387324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*Oc1ccc(OC(=O)c2cc(OCCCCCCCCCOCC3CCCN3c3ccc([N...</td>\n",
       "      <td>13.703218</td>\n",
       "      <td>13.703218</td>\n",
       "      <td>0.068062</td>\n",
       "      <td>-0.686332</td>\n",
       "      <td>0.014164</td>\n",
       "      <td>15.885714</td>\n",
       "      <td>965.154</td>\n",
       "      <td>896.610</td>\n",
       "      <td>964.483374</td>\n",
       "      <td>...</td>\n",
       "      <td>2.425533</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.355470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              SMILES  MaxAbsEStateIndex  \\\n",
       "0                         *CC(*)c1ccccc1C(=O)OCCCCCC          12.144536   \n",
       "1  *Nc1ccc([C@H](CCC)c2ccc(C3(c4ccc([C@@H](CCC)c5...           3.523412   \n",
       "2  *Oc1ccc(S(=O)(=O)c2ccc(Oc3ccc(C4(c5ccc(Oc6ccc(...          13.714745   \n",
       "3  *Nc1ccc(-c2c(-c3ccc(C)cc3)c(-c3ccc(C)cc3)c(N*)...           3.978671   \n",
       "4  *Oc1ccc(OC(=O)c2cc(OCCCCCCCCCOCC3CCCN3c3ccc([N...          13.703218   \n",
       "\n",
       "   MaxEStateIndex  MinAbsEStateIndex  MinEStateIndex       qed        SPS  \\\n",
       "0       12.144536           0.105927       -0.105927  0.500278  13.705882   \n",
       "1        3.523412           0.098918        0.098918  0.125364  16.777778   \n",
       "2       13.714745           0.107441       -3.829434  0.092387  16.301370   \n",
       "3        3.978671           0.054569       -0.202102  0.209590  11.523810   \n",
       "4       13.703218           0.068062       -0.686332  0.014164  15.885714   \n",
       "\n",
       "      MolWt  HeavyAtomMolWt   ExactMolWt  ...  spectral_radius  \\\n",
       "0   232.323         212.163   232.146330  ...         2.347213   \n",
       "1   598.919         544.487   598.428700  ...         2.512983   \n",
       "2  1003.207         952.807  1002.289625  ...         2.494566   \n",
       "3   542.726         508.454   542.272199  ...         2.598093   \n",
       "4   965.154         896.610   964.483374  ...         2.425533   \n",
       "\n",
       "   number_of_cycles  number_of_stars  diameter  number_of_branches  Tg  \\\n",
       "0                 1                2        12                   4 NaN   \n",
       "1                 5                2        22                  13 NaN   \n",
       "2                10                2        45                  25 NaN   \n",
       "3                 6                2        13                  16 NaN   \n",
       "4                 6                2        43                  18 NaN   \n",
       "\n",
       "        FFV        Tc  Density  Rg  \n",
       "0  0.374645  0.205667      NaN NaN  \n",
       "1  0.370410       NaN      NaN NaN  \n",
       "2  0.378860       NaN      NaN NaN  \n",
       "3  0.387324       NaN      NaN NaN  \n",
       "4  0.355470       NaN      NaN NaN  \n",
       "\n",
       "[5 rows x 212 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_feat = pd.read_csv(\"RDKit_topological.csv\")\n",
    "data_feat = data_feat.dropna(axis = 1)\n",
    "data_train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "descriptor_names = data_feat.columns[2::].tolist()\n",
    "labels = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
    "data_feat = data_feat[['SMILES'] + descriptor_names]\n",
    "data_train = data_train[['SMILES'] + labels]\n",
    "\n",
    "data_concat = data_feat.merge(data_train, on = 'SMILES', how = 'inner')\n",
    "data_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace7c1bb",
   "metadata": {},
   "source": [
    "#### <b>Linear regression</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a023762e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITHOUT NORMALIZATION:\n",
      "For Tg and with 511 available datapoints, SRCC: -0.268, MAE: 96.442\n",
      "For FFV and with 7030 available datapoints, SRCC: nan, MAE: 0.021\n",
      "For Tc and with 737 available datapoints, SRCC: 0.857, MAE: 0.032\n",
      "For Density and with 613 available datapoints, SRCC: 0.400, MAE: 0.103\n",
      "For Rg and with 614 available datapoints, SRCC: 0.274, MAE: 3.415\n",
      "\n",
      "WITH NORMALIZATION:\n",
      "For Tg and with 511 available datapoints, SRCC: 0.660, MAE: 72.072\n",
      "For FFV and with 7030 available datapoints, SRCC: 0.885, MAE: 4.566\n",
      "For Tc and with 737 available datapoints, SRCC: 0.879, MAE: 0.031\n",
      "For Density and with 613 available datapoints, SRCC: 0.815, MAE: 19457889.937\n",
      "For Rg and with 614 available datapoints, SRCC: 0.754, MAE: 2.597\n"
     ]
    }
   ],
   "source": [
    "# for linear regression w/o normalization\n",
    "print(\"WITHOUT NORMALIZATION:\")\n",
    "for label in labels:\n",
    "    data_concat_prime = data_concat[descriptor_names + [label]]\n",
    "    data_concat_prime = data_concat_prime.dropna()\n",
    "    X, y = data_concat_prime[descriptor_names], data_concat_prime[label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    reg = LinearRegression().fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    print(f\"For {label} and with {len(X)} available datapoints, SRCC: {spearmanr(y_test, y_pred)[0]:.3f}, MAE: {mean_absolute_error(y_test, y_pred):.3f}\")\n",
    "\n",
    "# for linear regression w/ normalization\n",
    "print()\n",
    "print(\"WITH NORMALIZATION:\")\n",
    "for label in labels:\n",
    "    data_concat_prime = data_concat[descriptor_names + [label]].dropna()\n",
    "    X = data_concat_prime[descriptor_names]\n",
    "    y = data_concat_prime[label]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    #normalization (because might be sensitive)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "    reg = LinearRegression().fit(X_train_scaled, y_train)\n",
    "    y_pred = reg.predict(X_test_scaled)\n",
    "\n",
    "    print(f\"For {label} and with {len(X)} available datapoints, SRCC: {spearmanr(y_test, y_pred)[0]:.3f}, MAE: {mean_absolute_error(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e974cb3e",
   "metadata": {},
   "source": [
    "Couple of things:\n",
    "- What the.. Why is density's MAE so high but has a healthy SRCC LOL\n",
    "- Linear (and probably Kernel) regression are super sensitive to scales for features (as expected, but not to this degree)\n",
    "- When looking at the normalization results for linear regression, it can be shown that all labels apart from Tg, density and Rg have really good performances i.e. they are captured well with a linear regression (there are most likely variables that linearly correlate heavily with these labels - check EDA)\n",
    "- let us try using a nonlinear model.. we can use quadratic, but the feature space will become gigantic (N + N + N(N-1)/2), and we already have a good amount of features. let's try KRR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2333652",
   "metadata": {},
   "source": [
    "#### <b>Kernel Ridge Regression</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77125b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITHOUT NORMALIZATION:\n",
      "For Tg and with 511 available datapoints, SRCC: 0.399, MAE: 116.780\n",
      "For FFV and with 7030 available datapoints, SRCC: 0.215, MAE: 0.367\n",
      "For Tc and with 737 available datapoints, SRCC: 0.515, MAE: 0.251\n",
      "For Density and with 613 available datapoints, SRCC: 0.131, MAE: 1.015\n",
      "For Rg and with 614 available datapoints, SRCC: 0.227, MAE: 15.985\n",
      "\n",
      "WITH NORMALIZATION:\n",
      "For Tg and with 511 available datapoints, SRCC: 0.665, MAE: 100.042\n",
      "For FFV and with 7030 available datapoints, SRCC: 0.882, MAE: 0.367\n",
      "For Tc and with 737 available datapoints, SRCC: 0.886, MAE: 0.250\n",
      "For Density and with 613 available datapoints, SRCC: 0.848, MAE: 0.953\n",
      "For Rg and with 614 available datapoints, SRCC: 0.825, MAE: 16.412\n"
     ]
    }
   ],
   "source": [
    "# w/o normalization\n",
    "print(\"WITHOUT NORMALIZATION:\")\n",
    "for label in labels:\n",
    "    data_concat_prime = data_concat[descriptor_names + [label]]\n",
    "    data_concat_prime = data_concat_prime.dropna()\n",
    "    X, y = data_concat_prime[descriptor_names], data_concat_prime[label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    reg = KernelRidge().fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    print(f\"For {label} and with {len(X)} available datapoints, SRCC: {spearmanr(y_test, y_pred)[0]:.3f}, MAE: {mean_absolute_error(y_test, y_pred):.3f}\")\n",
    "\n",
    "# w/ normalization\n",
    "print()\n",
    "print(\"WITH NORMALIZATION:\")\n",
    "for label in labels:\n",
    "    data_concat_prime = data_concat[descriptor_names + [label]].dropna()\n",
    "    X = data_concat_prime[descriptor_names]\n",
    "    y = data_concat_prime[label]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    #normalization (because might be sensitive)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "    reg = KernelRidge().fit(X_train_scaled, y_train)\n",
    "    y_pred = reg.predict(X_test_scaled)\n",
    "\n",
    "    print(f\"For {label} and with {len(X)} available datapoints, SRCC: {spearmanr(y_test, y_pred)[0]:.3f}, MAE: {mean_absolute_error(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccf0ed0",
   "metadata": {},
   "source": [
    "Couple of comments:\n",
    "- FFV, Tc, density predictions improved and are, IMO, quite sufficient right now\n",
    "- Tg makes me quite nervous - it barely improved from linear regression; maybe representation is poor (future work)\n",
    "- This doesn't mean that we should count KRR out immediately; these are baseline model hyperparameters.. Gamma will play a relatively large role in this (we should tune both KRR and upcoming models like XGB)\n",
    "- KRR also struggles with variable-to-variable interactions; recall from EDA that there are many weakly correlated features with Tg - perhaps XGB can remedy this?\n",
    "- KRR may also struggle because we're working without feature selection for baseline models.. another reason why to do selection --> hyp opt. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc35e82",
   "metadata": {},
   "source": [
    "#### <b>XGBoost</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0577698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITHOUT NORMALIZATION:\n",
      "For Tg and with 498 available datapoints, SRCC: 0.703, MAE: 59.021\n",
      "For FFV and with 6761 available datapoints, SRCC: 0.928, MAE: 0.006\n",
      "For Tc and with 737 available datapoints, SRCC: 0.889, MAE: 0.028\n",
      "For Density and with 592 available datapoints, SRCC: 0.947, MAE: 0.023\n",
      "For Rg and with 612 available datapoints, SRCC: 0.756, MAE: 2.081\n",
      "\n",
      "WITH NORMALIZATION:\n",
      "For Tg and with 498 available datapoints, SRCC: 0.703, MAE: 59.021\n",
      "For FFV and with 6761 available datapoints, SRCC: 0.927, MAE: 0.006\n",
      "For Tc and with 737 available datapoints, SRCC: 0.892, MAE: 0.027\n",
      "For Density and with 592 available datapoints, SRCC: 0.947, MAE: 0.023\n",
      "For Rg and with 612 available datapoints, SRCC: 0.755, MAE: 2.081\n"
     ]
    }
   ],
   "source": [
    "# w/o normalization\n",
    "print(\"WITHOUT NORMALIZATION:\")\n",
    "for label in labels:\n",
    "    data_concat_prime = data_concat[descriptor_names + [label]]\n",
    "    data_concat_prime = data_concat_prime.dropna()\n",
    "    Q1 = data_concat_prime[label].quantile(0.25)\n",
    "    Q3 = data_concat_prime[label].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
    "    data_concat_prime = data_concat_prime[(data_concat_prime[label] >= lower) & (data_concat_prime[label] <= upper)]\n",
    "    data_concat_prime = data_concat_prime.clip(upper = 1e6)\n",
    "    \n",
    "    X, y = data_concat_prime[descriptor_names], data_concat_prime[label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    reg = xgb.XGBRegressor().fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    print(f\"For {label} and with {len(X)} available datapoints, SRCC: {spearmanr(y_test, y_pred)[0]:.3f}, MAE: {mean_absolute_error(y_test, y_pred):.3f}\")\n",
    "\n",
    "# w/ normalization\n",
    "print()\n",
    "print(\"WITH NORMALIZATION:\")\n",
    "for label in labels:\n",
    "    data_concat_prime = data_concat[descriptor_names + [label]].dropna()\n",
    "    Q1 = data_concat_prime[label].quantile(0.25)\n",
    "    Q3 = data_concat_prime[label].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
    "    data_concat_prime = data_concat_prime[(data_concat_prime[label] >= lower) & (data_concat_prime[label] <= upper)]\n",
    "    data_concat_prime = data_concat_prime.clip(upper = 1e6)\n",
    "    X = data_concat_prime[descriptor_names]\n",
    "    y = data_concat_prime[label]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    #normalization (because might be sensitive)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "    reg = xgb.XGBRegressor().fit(X_train_scaled, y_train)\n",
    "    y_pred = reg.predict(X_test_scaled)\n",
    "\n",
    "    print(f\"For {label} and with {len(X)} available datapoints, SRCC: {spearmanr(y_test, y_pred)[0]:.3f}, MAE: {mean_absolute_error(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19ea750",
   "metadata": {},
   "source": [
    "#### <b>We can try TabPFN; shown to work on small data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e295c6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn import TabPFNRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e61f9de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITHOUT NORMALIZATION:\n",
      "For Tg and with 511 available datapoints, SRCC: 0.751, MAE: 52.313\n",
      "For FFV and with 7030 available datapoints, SRCC: 0.966, MAE: 0.005\n",
      "For Tc and with 737 available datapoints, SRCC: 0.909, MAE: 0.026\n",
      "For Density and with 613 available datapoints, SRCC: 0.916, MAE: 0.031\n",
      "For Rg and with 614 available datapoints, SRCC: 0.868, MAE: 1.608\n",
      "\n",
      "WITH NORMALIZATION:\n",
      "For Tg and with 511 available datapoints, SRCC: 0.718, MAE: 77.988\n",
      "For FFV and with 7030 available datapoints, SRCC: 0.319, MAE: 0.083\n",
      "For Tc and with 737 available datapoints, SRCC: 0.778, MAE: 0.122\n",
      "For Density and with 613 available datapoints, SRCC: 0.569, MAE: 0.174\n",
      "For Rg and with 614 available datapoints, SRCC: 0.162, MAE: 8.326\n"
     ]
    }
   ],
   "source": [
    "# w/o normalization\n",
    "print(\"WITHOUT NORMALIZATION:\")\n",
    "for label in labels:\n",
    "    data_concat_prime = data_concat[descriptor_names + [label]]\n",
    "    data_concat_prime = data_concat_prime.dropna()\n",
    "    data_concat_prime = data_concat_prime.clip(upper = 1e6)\n",
    "    X, y = data_concat_prime[descriptor_names], data_concat_prime[label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    reg = TabPFNRegressor() #pre-trained on synthetic data, apparently\n",
    "    #reg = TabPFNRegressor.create_default_for_version(ModelVersion.V2)\n",
    "    reg.fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    print(f\"For {label} and with {len(X)} available datapoints, SRCC: {spearmanr(y_test, y_pred)[0]:.3f}, MAE: {mean_absolute_error(y_test, y_pred):.3f}\")\n",
    "\n",
    "# w/ normalization\n",
    "print()\n",
    "print(\"WITH NORMALIZATION:\")\n",
    "for label in labels:\n",
    "    data_concat_prime = data_concat[descriptor_names + [label]].dropna()\n",
    "    data_concat_prime = data_concat_prime.clip(upper = 1e6)\n",
    "    X = data_concat_prime[descriptor_names]\n",
    "    y = data_concat_prime[label]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    #normalization (because might be sensitive)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "    reg = TabPFNRegressor() #pre-trained on synthetic data, apparently\n",
    "    #reg = TabPFNRegressor.create_default_for_version(ModelVersion.V2)\n",
    "    reg.fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test_scaled)\n",
    "\n",
    "    print(f\"For {label} and with {len(X)} available datapoints, SRCC: {spearmanr(y_test, y_pred)[0]:.3f}, MAE: {mean_absolute_error(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1019525a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a40e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33613222",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
